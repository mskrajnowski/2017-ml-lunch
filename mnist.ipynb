{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller sample for development\n",
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:1000], y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 28, 28), (5000,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 28, 28), (1000,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 10), (1000, 10))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_batch(x, y):\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(12, 3))\n",
    "    axes = axes.reshape(16)\n",
    "    for axis in axes:\n",
    "        axis.set_axis_off()\n",
    "        \n",
    "    for image, label, axis in zip(x[:16], y[:16], axes):\n",
    "        axis.imshow(image, cmap='gray')\n",
    "        axis.set_title(label.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAADPCAYAAAAQ0dwQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV49bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3dbd9e3a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_batch(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def evaluate(layers):\n",
    "    model = Sequential(layers)\n",
    "    model.compile(\n",
    "        optimizer='nadam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    display(model.summary())\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)\n",
    "\n",
    "    labels = y_test.argmax()\n",
    "    predictions = model.predict(x_test)\n",
    "    predicted_labels = predictions.argmax()\n",
    "    prediction_certainty = predictions.max(axis=1)\n",
    "    \n",
    "    y_test\n",
    "    \n",
    "    correct = np.where(predicted_labels == labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(10),\n",
    "])\n",
    "model_1.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.0248 - acc: 0.1568 - val_loss: 10.5533 - val_acc: 0.2190\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.8824 - acc: 0.1776 - val_loss: 10.2982 - val_acc: 0.2060\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.1893 - acc: 0.1896 - val_loss: 9.6653 - val_acc: 0.2020\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.4102 - acc: 0.1492 - val_loss: 10.1484 - val_acc: 0.1130\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.0370 - acc: 0.1182 - val_loss: 10.4179 - val_acc: 0.1240\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.2145 - acc: 0.1126 - val_loss: 10.6409 - val_acc: 0.1210\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.0085 - acc: 0.1134 - val_loss: 8.4545 - val_acc: 0.1270\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.7004 - acc: 0.1314 - val_loss: 8.7046 - val_acc: 0.1900\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.2456 - acc: 0.1704 - val_loss: 8.8176 - val_acc: 0.1840\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.8208 - acc: 0.1668 - val_loss: 10.9954 - val_acc: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3dc4dbb898>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "model_2.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s - loss: 10.2122 - acc: 0.3584 - val_loss: 9.0066 - val_acc: 0.4330\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.3889 - acc: 0.4754 - val_loss: 8.3356 - val_acc: 0.4770\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.0207 - acc: 0.4980 - val_loss: 7.8889 - val_acc: 0.5050\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.6087 - acc: 0.5250 - val_loss: 7.7200 - val_acc: 0.5170\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.5888 - acc: 0.5264 - val_loss: 7.6265 - val_acc: 0.5230\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.3556 - acc: 0.5408 - val_loss: 7.5394 - val_acc: 0.5300\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.2724 - acc: 0.5464 - val_loss: 7.1333 - val_acc: 0.5560\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.1782 - acc: 0.5536 - val_loss: 7.3009 - val_acc: 0.5450\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.3013 - acc: 0.5450 - val_loss: 7.7562 - val_acc: 0.5170\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s - loss: 7.2759 - acc: 0.5466 - val_loss: 7.4270 - val_acc: 0.5380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3dc4a01e80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,986\n",
      "Trainable params: 9,418\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "model_3.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.7377 - acc: 0.7766 - val_loss: 0.5066 - val_acc: 0.8550\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.3547 - acc: 0.8990 - val_loss: 0.4708 - val_acc: 0.8710\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2993 - acc: 0.9156 - val_loss: 0.4910 - val_acc: 0.8750\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2721 - acc: 0.9260 - val_loss: 0.4950 - val_acc: 0.8790\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2437 - acc: 0.9258 - val_loss: 0.5027 - val_acc: 0.8770\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2272 - acc: 0.9344 - val_loss: 0.5145 - val_acc: 0.8790\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2186 - acc: 0.9344 - val_loss: 0.5266 - val_acc: 0.8770\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.2042 - acc: 0.9376 - val_loss: 0.5221 - val_acc: 0.8860\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.1936 - acc: 0.9414 - val_loss: 0.5402 - val_acc: 0.8720\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s - loss: 0.1986 - acc: 0.9420 - val_loss: 0.5739 - val_acc: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3dc45ae9b0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.4750 - acc: 0.4116 - val_loss: 9.6225 - val_acc: 0.4030\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.4101 - acc: 0.4160 - val_loss: 9.5882 - val_acc: 0.4050\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.4227 - acc: 0.4152 - val_loss: 9.3146 - val_acc: 0.4200\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.2450 - acc: 0.4256 - val_loss: 8.6248 - val_acc: 0.4640\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.8674 - acc: 0.4496 - val_loss: 8.5526 - val_acc: 0.4690\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s - loss: 9.1526 - acc: 0.4318 - val_loss: 9.0128 - val_acc: 0.4390\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.9683 - acc: 0.4432 - val_loss: 8.7854 - val_acc: 0.4540\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.7694 - acc: 0.4558 - val_loss: 9.1712 - val_acc: 0.4310\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.9120 - acc: 0.4468 - val_loss: 9.1873 - val_acc: 0.4300\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s - loss: 8.7319 - acc: 0.4580 - val_loss: 8.8535 - val_acc: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3dd4dc42b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
